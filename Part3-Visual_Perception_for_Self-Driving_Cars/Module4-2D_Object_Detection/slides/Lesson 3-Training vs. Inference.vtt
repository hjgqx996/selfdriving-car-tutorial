WEBVTT

1
00:00:00.000 --> 00:00:10.000
[MUSIC]

2
00:00:14.219 --> 00:00:19.034
Last lesson we learned a baseline approach
to perform object detection using

3
00:00:19.034 --> 00:00:20.680
convenance.

4
00:00:20.680 --> 00:00:25.630
However, processing all the anchors in our
anchor grid led to multiple bounding boxes

5
00:00:25.630 --> 00:00:30.150
being detected per object rather than
the expected single locks per object.

6
00:00:31.150 --> 00:00:34.890
This lesson, we will discuss the final
components we need to build and

7
00:00:34.890 --> 00:00:38.169
train convolutional neural networks for
2D object detection.

8
00:00:39.260 --> 00:00:44.100
Specifically, you will learn how to handle
multiple regressed anchors per object

9
00:00:44.100 --> 00:00:47.630
during training through
mini batch selection and

10
00:00:47.630 --> 00:00:51.180
during inference through
non-maximum suppression.

11
00:00:51.180 --> 00:00:53.240
Let's begin by reviewing
neural network training.

12
00:00:54.290 --> 00:00:57.840
We are given our cond net model and
training data pairs, x,

13
00:00:57.840 --> 00:01:02.129
the input image, and f star of x,
the bounding box locations and class.

14
00:01:03.340 --> 00:01:05.960
We want to approximate f star of x

15
00:01:05.960 --> 00:01:10.550
with our output bounding boxes
y equal to f of x and theta.

16
00:01:11.930 --> 00:01:16.470
Recall from last week that we performed
training by first evaluating a loss

17
00:01:16.470 --> 00:01:19.770
function that measures how similar
our predicted bounding boxes

18
00:01:19.770 --> 00:01:21.760
are to the ground truth bounding boxes.

19
00:01:22.810 --> 00:01:26.970
Then we feed the resultant
loss function to our optimizer

20
00:01:26.970 --> 00:01:31.290
that outputs a new set of parameters theta
to be used for the second iteration.

21
00:01:32.290 --> 00:01:34.860
Notice that both the feature extractor and

22
00:01:34.860 --> 00:01:37.210
the output layers
are modified during training.

23
00:01:38.450 --> 00:01:41.200
Now if f star of x and

24
00:01:41.200 --> 00:01:44.870
f of x theta are one to one,
our problem would have been easy.

25
00:01:44.870 --> 00:01:48.910
However, the outputs of our
network is multiple boxes

26
00:01:48.910 --> 00:01:51.330
that can be associated with
a single ground truth box.

27
00:01:52.620 --> 00:01:54.750
Let's see how we can work
to resolve this issue.

28
00:01:55.890 --> 00:02:00.039
Remember that for each pixel in
the feature map, we associate k anchors.

29
00:02:01.170 --> 00:02:03.260
Where do these anchors appear
in the original image?

30
00:02:04.370 --> 00:02:08.550
As we've learnt earlier, our feature
extractor reduces the resolution

31
00:02:08.550 --> 00:02:11.480
of the initial input by a factor of 32.

32
00:02:11.480 --> 00:02:14.890
That means that if we associate
every pixel in the feature map

33
00:02:14.890 --> 00:02:19.120
with a set of anchors, these anchors
will be transferred to the initial

34
00:02:19.120 --> 00:02:23.020
image by placing them on
a grid with stride 32.

35
00:02:23.020 --> 00:02:27.420
We can then visualize the ground truth
bounding box alongside these anchors.

36
00:02:27.420 --> 00:02:30.400
You can notice that some
anchors overlap and some don't.

37
00:02:32.220 --> 00:02:34.770
We quantify this overlap with IOU and

38
00:02:34.770 --> 00:02:37.830
categorize the anchors
into two categories.

39
00:02:37.830 --> 00:02:42.520
We first specify two IOU thresholds,
a positive anchor threshold, and

40
00:02:42.520 --> 00:02:43.680
a negative anchor threshold.

41
00:02:45.530 --> 00:02:49.390
Any anchor with an IOU greater
than the positive anchor threshold

42
00:02:49.390 --> 00:02:51.150
is called a positive anchor.

43
00:02:51.150 --> 00:02:55.450
And similarly, any anchor with an IOU
less than the negative anchor threshold

44
00:02:55.450 --> 00:02:56.470
is called a negative anchor.

45
00:02:58.090 --> 00:03:02.480
Any anchor with an IOU in between
the two thresholds is fully discarded.

46
00:03:03.760 --> 00:03:07.890
So now, how do we use these positive and
negative anchors in training?

47
00:03:07.890 --> 00:03:11.670
Let's now see how to assign the
classification and regression targets for

48
00:03:11.670 --> 00:03:13.920
the positive and negative anchors.

49
00:03:13.920 --> 00:03:16.990
For classification,
we want the neural network to predict

50
00:03:16.990 --> 00:03:20.550
that the negative anchors
belong to the background class.

51
00:03:20.550 --> 00:03:24.100
Background is usually a class we
add to our classes of interest

52
00:03:24.100 --> 00:03:26.990
to describe anything
non-included in these classes.

53
00:03:28.500 --> 00:03:32.140
On the other hand, we want the neural
network to assign ground truth class

54
00:03:32.140 --> 00:03:34.740
to any positive anchor
intersecting that ground truth.

55
00:03:36.200 --> 00:03:40.130
For regression, we want to shift the
parameters of the positive anchor to be

56
00:03:40.130 --> 00:03:43.320
aligned with those of
the ground truth bounding box.

57
00:03:43.320 --> 00:03:46.745
The negative anchors are not used
in bounding box regression as they

58
00:03:46.745 --> 00:03:48.320
are assumed to be background.

59
00:03:49.963 --> 00:03:54.578
This approach of handling multiple
regressed anchors during training is not

60
00:03:54.578 --> 00:03:55.859
free from problems.

61
00:03:56.900 --> 00:03:59.940
The proposed IOU thresholding
mechanism results in

62
00:03:59.940 --> 00:04:03.060
most of the regressed anchors
being negative anchors.

63
00:04:03.060 --> 00:04:07.150
When training with all these anchors,
the network will be observing far more

64
00:04:07.150 --> 00:04:12.020
negative than positive examples leading
to a biased towards the negative class.

65
00:04:13.150 --> 00:04:15.980
The solution to this problem
is actually quite simple,

66
00:04:15.980 --> 00:04:20.320
instead of using all anchors to compute
the lost function, we sample the chosen

67
00:04:20.320 --> 00:04:25.340
minibatch size with a three to one
ratio of negative to positive anchors.

68
00:04:26.820 --> 00:04:31.910
The negatives are chosen through a process
called online hard negative mining,

69
00:04:31.910 --> 00:04:35.950
in which negative minibatch members
are chosen as the negative anchors

70
00:04:35.950 --> 00:04:37.679
with the highest classification loss.

71
00:04:38.830 --> 00:04:42.340
This means that where we've training
to fix the biggest errors in negative

72
00:04:42.340 --> 00:04:43.240
classification.

73
00:04:45.040 --> 00:04:49.930
As an example, if we have a minibatch
of 64 examples, the negative minibatch

74
00:04:49.930 --> 00:04:54.680
will be the 48 negative examples with
the highest classification loss, and

75
00:04:54.680 --> 00:04:58.330
the 16 remaining anchors
will be positive anchors.

76
00:04:58.330 --> 00:05:03.180
If the number of positives is less than
16, we either copy some of the positives

77
00:05:03.180 --> 00:05:07.470
to pad the minibatch or fill the remaining
spots with negative anchors.

78
00:05:09.910 --> 00:05:14.280
As we described earlier last week, we
used the cross entropy loss function for

79
00:05:14.280 --> 00:05:17.360
the classification head of our ConvNet.

80
00:05:17.360 --> 00:05:21.740
The total classification loss is
the average of the cross entropy loss

81
00:05:21.740 --> 00:05:23.450
of all anchors in the minibatch.

82
00:05:24.800 --> 00:05:28.880
The normalization constant and
total is the chosen minibatch size.

83
00:05:30.500 --> 00:05:34.040
Si is the output of
the classification head.

84
00:05:34.040 --> 00:05:37.220
And Si star is the ground
truth classification

85
00:05:37.220 --> 00:05:40.230
which is set to background for
negative anchors and

86
00:05:40.230 --> 00:05:43.710
to the class of the ground truth
bounding box for the positive anchors.

87
00:05:45.460 --> 00:05:49.510
For regression, we use the L2
norm loss in a similar manner.

88
00:05:49.510 --> 00:05:54.290
However, we only attempt to modify
an anchor if it is a positive anchor.

89
00:05:54.290 --> 00:05:59.780
This is expressed mathematically
with a multiplier Pi on the L2 norm.

90
00:05:59.780 --> 00:06:03.460
It is 0 if the anchor is negative and
1 if the anchor is positive.

91
00:06:05.930 --> 00:06:10.010
To normalize, we divide by
the number of positive anchors, and

92
00:06:10.010 --> 00:06:15.000
just as a reminder, bi star is the ground
truth bounding box representation,

93
00:06:15.000 --> 00:06:17.130
while bi is the estimated bounding box.

94
00:06:18.820 --> 00:06:22.800
Remember that we don't directly estimate
box parameters, but rather, we modify

95
00:06:22.800 --> 00:06:27.180
the anchor parameters by an additive
residual or a multiplicative scale.

96
00:06:27.180 --> 00:06:30.197
So bi must be constructed
from the estimated residuals.

97
00:06:32.069 --> 00:06:35.606
Let's visualize what we are trying to
teach the neural network to learn with

98
00:06:35.606 --> 00:06:36.719
these loss functions.

99
00:06:37.840 --> 00:06:41.010
Given an input image,
a ground truth bounding box, and

100
00:06:41.010 --> 00:06:46.330
a set of input anchors from the anchor
prior, we are teaching the neural

101
00:06:46.330 --> 00:06:52.570
network to classify anchors as containing
background in purple or a car in blue.

102
00:06:52.570 --> 00:06:57.060
This is done by minimizing the cross
entropy loss defined above.

103
00:06:57.060 --> 00:07:01.310
Then we want the neural network to move
only anchors that contain a class of

104
00:07:01.310 --> 00:07:06.390
interest, in a way that matches
the closest ground truth bounding box.

105
00:07:06.390 --> 00:07:09.827
This is done by minimizing
the L2 norm loss defined above.

106
00:07:11.040 --> 00:07:15.670
By now, you should have a good grasp on
how to handle multiple output boxes for

107
00:07:15.670 --> 00:07:17.560
object during training.

108
00:07:17.560 --> 00:07:22.300
But what do we do when we run the neural
network in real time during inference?

109
00:07:22.300 --> 00:07:26.850
Remember, during inference, we do not have
ground truths to determine positive and

110
00:07:26.850 --> 00:07:30.810
negative anchors and
we do not evaluate loss functions.

111
00:07:30.810 --> 00:07:34.670
We just want a single output
box per object in the scene.

112
00:07:35.930 --> 00:07:40.590
Here is when non max suppression comes
into play, an extremely powerful approach

113
00:07:40.590 --> 00:07:43.930
to improving inference output for
anchor based neuron networks.

114
00:07:43.930 --> 00:07:48.640
Non-max suppression takes as
an input a list of predicted

115
00:07:48.640 --> 00:07:53.120
boundary boxed b, and each bounding
blocks is comprised of the regressed

116
00:07:53.120 --> 00:07:55.140
coordinates in the class output score.

117
00:07:56.330 --> 00:08:00.500
It also needs as an input a predefined
IOU threshold which we'll call ada.

118
00:08:01.630 --> 00:08:03.840
The algorithm then goes as follows,

119
00:08:03.840 --> 00:08:08.860
we first sort the bounding boxes in
list B according to their output score.

120
00:08:08.860 --> 00:08:12.659
We also initialize an empty set
D to hold output bounding boxes.

121
00:08:13.790 --> 00:08:19.800
We then proceed to iterate overall
elements in the sorted box list B bar.

122
00:08:19.800 --> 00:08:23.100
Inside the for loop,
we first determine the box B max with

123
00:08:23.100 --> 00:08:27.530
the highest score in the list B, which
should be the first element in B bar.

124
00:08:28.870 --> 00:08:32.830
We then remove this bounding box
from the bounding box set D bar and

125
00:08:32.830 --> 00:08:34.410
add it to the output set D.

126
00:08:35.730 --> 00:08:39.700
Next, we find all boxes
remaining in the set B bar

127
00:08:39.700 --> 00:08:44.830
that have an IOU greater
than ada with the box B max.

128
00:08:44.830 --> 00:08:50.230
These boxes significantly overlap
with the current maximum box, B max.

129
00:08:50.230 --> 00:08:55.010
Any box that satisfies this condition
gets removed from the list B bar.

130
00:08:55.010 --> 00:08:58.930
We keep iterating through the list
B bar until is empty, and

131
00:08:58.930 --> 00:09:00.490
then we return the list D.

132
00:09:01.680 --> 00:09:04.690
D now contains a single
bounding box per object.

133
00:09:05.840 --> 00:09:09.350
Let's go through a visual example to
understand how non-max suppression

134
00:09:09.350 --> 00:09:10.808
algorithms work in practice.

135
00:09:12.958 --> 00:09:17.500
Let's assume that we have sorted
the bounding box list in decreasing order.

136
00:09:18.840 --> 00:09:21.940
We also show the score
list explicitly here for

137
00:09:21.940 --> 00:09:26.630
better visibility on how
non-max suppression works.

138
00:09:26.630 --> 00:09:32.390
b max will be the first bounding
box of the sorted list B bar.

139
00:09:32.390 --> 00:09:36.260
We then proceed to compare
each bounding box to b max.

140
00:09:36.260 --> 00:09:41.780
In this case, only one box, B3,
has a non zero IOU with b max.

141
00:09:41.780 --> 00:09:46.880
We compute that IOU and
compare it with our IOU threshold ada.

142
00:09:46.880 --> 00:09:50.660
In this case, the IOU is greater
than the threshold ada, so

143
00:09:50.660 --> 00:09:54.200
we remove box 3 from the list B bar.

144
00:09:54.200 --> 00:09:57.508
We repeat the process for the next
highest score that remains in the list.

145
00:09:59.725 --> 00:10:05.270
Again, only one box has a non-zero
IOU with b max, box 4 in this case.

146
00:10:06.380 --> 00:10:09.450
Computing the IOU and
comparing with the threshold,

147
00:10:09.450 --> 00:10:14.750
we eliminate box 4 from list B bar,
and add box 2 to the output list D.

148
00:10:15.990 --> 00:10:19.248
We notice that our initial list,
B bar, is now empty.

149
00:10:19.248 --> 00:10:24.240
So our non-max suppression algorithm
exits and returns the output box list D

150
00:10:24.240 --> 00:10:27.490
that contains one bounding
box per object as expected.

151
00:10:28.870 --> 00:10:32.870
Congratulations, you have now completed
the content required to train and

152
00:10:32.870 --> 00:10:38.130
deploy ConvNet based 2D object
detectors for self-driving cars.

153
00:10:38.130 --> 00:10:42.870
In this video, we explored how to adjust
network output during training to maintain

154
00:10:42.870 --> 00:10:47.510
class balance, and to restrict
network output during inference

155
00:10:47.510 --> 00:10:50.180
to select one output
bounding box per object.

156
00:10:51.340 --> 00:10:55.190
In the next lesson, we will discuss
how we can use the output of these 2D

157
00:10:55.190 --> 00:11:00.170
object detectors for a variety of tasks
that are important for self driving cars.

158
00:11:00.170 --> 00:11:05.680
Including transforming 2D object
detection to 3D, tracking object motion,

159
00:11:05.680 --> 00:11:10.170
and applying 2D object detection to
traffic sign, and signal detection.

160
00:11:10.170 --> 00:11:10.670
See you there.

161
00:11:10.670 --> 00:11:20.670
[MUSIC]