WEBVTT

1
00:00:19.460 --> 00:00:21.990
Hello everyone, and welcome to

2
00:00:21.990 --> 00:00:23.550
the visual perception course of

3
00:00:23.550 --> 00:00:25.875
the self-driving
car specialization.

4
00:00:25.875 --> 00:00:28.520
You've probably noticed
that most major players in

5
00:00:28.520 --> 00:00:30.980
the autonomous driving
industry have a camera as

6
00:00:30.980 --> 00:00:33.680
their primary sensor in
their vehicle sensor suite.

7
00:00:33.680 --> 00:00:35.420
The camera is a rich sensor that

8
00:00:35.420 --> 00:00:37.760
captures incredible detail
about the environment around

9
00:00:37.760 --> 00:00:40.790
the vehicle but requires
extensive processing to make

10
00:00:40.790 --> 00:00:43.910
use of the information that's
available in that image.

11
00:00:43.910 --> 00:00:45.410
Throughout this course,
you will get

12
00:00:45.410 --> 00:00:48.650
hands on experience on how to
algorithmically manipulate

13
00:00:48.650 --> 00:00:51.240
camera images to
extract information,

14
00:00:51.240 --> 00:00:53.195
useful, not just for
autonomous driving

15
00:00:53.195 --> 00:00:55.330
but for robotic
perception in general.

16
00:00:55.330 --> 00:00:57.920
In the first module in
week one of this course,

17
00:00:57.920 --> 00:00:59.900
we will provide you
with an overview of

18
00:00:59.900 --> 00:01:01.550
important concepts related to

19
00:01:01.550 --> 00:01:03.335
cameras and computer vision.

20
00:01:03.335 --> 00:01:05.150
This module is only meant as

21
00:01:05.150 --> 00:01:08.105
a high level summary of
the basics of computer vision.

22
00:01:08.105 --> 00:01:09.920
So, we'll move quickly
through a large number of

23
00:01:09.920 --> 00:01:13.510
topics to develop more in-depth
knowledge in this area,

24
00:01:13.510 --> 00:01:15.545
have a look at
the computer vision courses

25
00:01:15.545 --> 00:01:17.555
also available on Coursera.

26
00:01:17.555 --> 00:01:19.880
In this first video,
we will highlight why

27
00:01:19.880 --> 00:01:22.715
the camera is a critical sensor
for autonomous driving.

28
00:01:22.715 --> 00:01:24.380
We will then briefly introduce

29
00:01:24.380 --> 00:01:27.110
the concept of
image formation and present

30
00:01:27.110 --> 00:01:29.360
the pinhole camera model
which captures

31
00:01:29.360 --> 00:01:31.250
the essential elements
of how a camera

32
00:01:31.250 --> 00:01:33.385
works in a simple
and elegant manner.

33
00:01:33.385 --> 00:01:34.670
We'll then show you

34
00:01:34.670 --> 00:01:36.890
an example of
a historic camera design

35
00:01:36.890 --> 00:01:38.720
which used the pinhole
principle to

36
00:01:38.720 --> 00:01:41.300
create some of the earliest
images ever recorded.

37
00:01:41.300 --> 00:01:43.520
The pinhole model will
form the basis of

38
00:01:43.520 --> 00:01:45.830
our discussions in
the next video where we

39
00:01:45.830 --> 00:01:47.750
investigate how to
project points from

40
00:01:47.750 --> 00:01:50.830
the world into the camera
imaging sensor.

41
00:01:50.830 --> 00:01:53.995
Of all the common
self-driving car sensors,

42
00:01:53.995 --> 00:01:55.850
the camera is the sensor
that provides

43
00:01:55.850 --> 00:01:57.949
the most detailed
appearance information

44
00:01:57.949 --> 00:01:59.735
from objects in the environment.

45
00:01:59.735 --> 00:02:02.000
Appearance information
is particularly

46
00:02:02.000 --> 00:02:03.620
useful for scene understanding

47
00:02:03.620 --> 00:02:06.105
tasks such as object detection,

48
00:02:06.105 --> 00:02:08.420
segmentation and identification.

49
00:02:08.420 --> 00:02:11.360
Appearance information is
what allows us to distinguish

50
00:02:11.360 --> 00:02:13.970
between road signs or
traffic lights states,

51
00:02:13.970 --> 00:02:15.650
to track turn signals and resolve

52
00:02:15.650 --> 00:02:18.290
overlapping vehicles
into separate instances.

53
00:02:18.290 --> 00:02:20.630
Because of its high
resolution output,

54
00:02:20.630 --> 00:02:22.100
the camera is able to collect and

55
00:02:22.100 --> 00:02:23.570
provide orders of magnitude,

56
00:02:23.570 --> 00:02:25.640
more information than
other sensors used in

57
00:02:25.640 --> 00:02:29.225
self-driving while still
being relatively inexpensive.

58
00:02:29.225 --> 00:02:32.750
The combination of high valued
appearance information and

59
00:02:32.750 --> 00:02:34.610
low cost make
the camera an essential

60
00:02:34.610 --> 00:02:36.665
component of our sensor suite.

61
00:02:36.665 --> 00:02:38.330
Let us see how
the camera manages to

62
00:02:38.330 --> 00:02:40.505
collect this huge amount
of information.

63
00:02:40.505 --> 00:02:44.015
A camera is a passive
external receptive sensor.

64
00:02:44.015 --> 00:02:47.089
It uses an imaging sensor
to capture information

65
00:02:47.089 --> 00:02:50.705
conveyed by light rays emitted
from objects in the world.

66
00:02:50.705 --> 00:02:53.600
This was originally done with
film but nowadays we use

67
00:02:53.600 --> 00:02:55.790
rather sophisticated
silicon chips

68
00:02:55.790 --> 00:02:57.395
to gather this information.

69
00:02:57.395 --> 00:02:59.450
Light is reflected
from every point

70
00:02:59.450 --> 00:03:01.340
on an object in all directions,

71
00:03:01.340 --> 00:03:02.690
and a portion of these rays

72
00:03:02.690 --> 00:03:04.715
travel towards the camera sensor.

73
00:03:04.715 --> 00:03:06.830
Look at the car's reflected rays

74
00:03:06.830 --> 00:03:08.900
collected by our imaging surface.

75
00:03:08.900 --> 00:03:11.000
Do you think we will get
a good representation of

76
00:03:11.000 --> 00:03:14.725
the car on the image sensor
from this ray-pattern?

77
00:03:14.725 --> 00:03:16.730
Unfortunately, no.

78
00:03:16.730 --> 00:03:20.270
Using this basic open
sensor camera design,

79
00:03:20.270 --> 00:03:22.205
we will end up with blurry images

80
00:03:22.205 --> 00:03:24.050
because our imaging
sensor is collecting

81
00:03:24.050 --> 00:03:25.580
light rays from
multiple points on

82
00:03:25.580 --> 00:03:28.370
the object at the same
location on the sensor.

83
00:03:28.370 --> 00:03:30.230
The solution to our problem is to

84
00:03:30.230 --> 00:03:31.730
put a barrier in front of

85
00:03:31.730 --> 00:03:33.890
the imaging sensor
with a tiny hole

86
00:03:33.890 --> 00:03:35.645
or aperture in its center.

87
00:03:35.645 --> 00:03:37.910
The barrier allows
only a small number

88
00:03:37.910 --> 00:03:39.800
of light rays to pass
through the aperture,

89
00:03:39.800 --> 00:03:41.735
reducing the blurriness
of the image.

90
00:03:41.735 --> 00:03:44.210
This model is called
the pinhole camera model

91
00:03:44.210 --> 00:03:45.860
and describes the relationship

92
00:03:45.860 --> 00:03:47.750
between a point in
the world and it's

93
00:03:47.750 --> 00:03:50.570
corresponding projection
on the image plane.

94
00:03:50.570 --> 00:03:52.610
The two most important parameters

95
00:03:52.610 --> 00:03:54.700
in a pinhole camera model are

96
00:03:54.700 --> 00:03:56.790
the distance between
the pinhole and

97
00:03:56.790 --> 00:03:59.525
the image plane which we
call the focal length,

98
00:03:59.525 --> 00:04:01.700
the focal length
defines the size of

99
00:04:01.700 --> 00:04:04.340
the object projected
onto the image and plays

100
00:04:04.340 --> 00:04:06.530
an important role
in the camera focus

101
00:04:06.530 --> 00:04:09.280
when using lenses to
improve camera performance.

102
00:04:09.280 --> 00:04:11.645
The coordinates of
the center of the pinhole,

103
00:04:11.645 --> 00:04:13.370
which we call the camera center,

104
00:04:13.370 --> 00:04:15.680
these coordinates to
find the location on

105
00:04:15.680 --> 00:04:16.790
the imaging sensor that

106
00:04:16.790 --> 00:04:18.800
the object projection
will inhabit.

107
00:04:18.800 --> 00:04:21.260
Although the pinhole
camera model is very simple,

108
00:04:21.260 --> 00:04:22.760
it works surprisingly well for

109
00:04:22.760 --> 00:04:25.040
representing the image
creation process.

110
00:04:25.040 --> 00:04:26.960
By identifying
the focal length and

111
00:04:26.960 --> 00:04:29.740
camera's center for
a specific camera configuration,

112
00:04:29.740 --> 00:04:33.380
we can mathematically describe
the location that a ray of

113
00:04:33.380 --> 00:04:34.850
light emanating from an object in

114
00:04:34.850 --> 00:04:37.565
the world will strike
the image plane.

115
00:04:37.565 --> 00:04:40.115
This allows us to form
a measurement model of

116
00:04:40.115 --> 00:04:42.140
image formation for use

117
00:04:42.140 --> 00:04:44.495
in state estimation
and object detection.

118
00:04:44.495 --> 00:04:46.160
A historical example of

119
00:04:46.160 --> 00:04:48.590
the pinhole camera model
is the camera obscura,

120
00:04:48.590 --> 00:04:51.545
which translates to
dark room camera in English.

121
00:04:51.545 --> 00:04:53.390
Historical evidence shows that

122
00:04:53.390 --> 00:04:55.730
this form of imaging
was discovered as early

123
00:04:55.730 --> 00:05:00.065
as 470 BC in Ancient
China and Greece.

124
00:05:00.065 --> 00:05:01.670
It's simple construction with

125
00:05:01.670 --> 00:05:03.350
a pinhole aperture in front of

126
00:05:03.350 --> 00:05:06.980
an imaging surface makes it
easy to recreate on your own,

127
00:05:06.980 --> 00:05:09.110
and is in fact a safe way to

128
00:05:09.110 --> 00:05:11.680
watch solar eclipse if
you're so inclined.

129
00:05:11.680 --> 00:05:13.640
We've come a long way since

130
00:05:13.640 --> 00:05:15.530
the invention of
the camera obscura.

131
00:05:15.530 --> 00:05:17.630
Current-day cameras
allow us to collect

132
00:05:17.630 --> 00:05:19.895
extremely high resolution data.

133
00:05:19.895 --> 00:05:22.355
They can operate in
low-light conditions

134
00:05:22.355 --> 00:05:23.660
or at a long range due to

135
00:05:23.660 --> 00:05:26.420
the advanced lens optics
that gather a large amount

136
00:05:26.420 --> 00:05:29.780
of light and focus it
accurately on the image plane.

137
00:05:29.780 --> 00:05:32.150
The resolution and sensitivity of

138
00:05:32.150 --> 00:05:34.730
camera sensors
continues to improve,

139
00:05:34.730 --> 00:05:35.960
making cameras one of the most

140
00:05:35.960 --> 00:05:38.495
ubiquitous sensors on the planet.

141
00:05:38.495 --> 00:05:40.685
How many cameras do
you think you own?

142
00:05:40.685 --> 00:05:43.835
You'd be surprised if you
stop to count them all.

143
00:05:43.835 --> 00:05:46.955
You'll have cameras in
your phones, in your car,

144
00:05:46.955 --> 00:05:48.950
on your laptop,
they are literally

145
00:05:48.950 --> 00:05:51.605
everywhere and in
every device we own today.

146
00:05:51.605 --> 00:05:54.650
These advances are also
extremely beneficial for

147
00:05:54.650 --> 00:05:57.920
understanding the environment
around a self-driving car.

148
00:05:57.920 --> 00:05:59.620
As we discussed in course one,

149
00:05:59.620 --> 00:06:01.490
cameras specifically designed for

150
00:06:01.490 --> 00:06:02.930
autonomous vehicles need to work

151
00:06:02.930 --> 00:06:04.640
well in a wide range of

152
00:06:04.640 --> 00:06:07.820
lighting conditions and
in distances to objects.

153
00:06:07.820 --> 00:06:09.800
These properties are
essential to driving

154
00:06:09.800 --> 00:06:11.945
safely in all
operating conditions.

155
00:06:11.945 --> 00:06:14.010
In this introductory lesson,

156
00:06:14.010 --> 00:06:15.650
you've learned the usefulness of

157
00:06:15.650 --> 00:06:18.245
the camera as a sensor
for autonomous driving.

158
00:06:18.245 --> 00:06:20.690
You also saw the pinhole
camera model

159
00:06:20.690 --> 00:06:22.150
in its most basic form,

160
00:06:22.150 --> 00:06:24.230
which we'll use
throughout this course to

161
00:06:24.230 --> 00:06:26.885
construct algorithms
for visual perception.

162
00:06:26.885 --> 00:06:28.910
In the next video, we will

163
00:06:28.910 --> 00:06:31.090
describe how an image is formed,

164
00:06:31.090 --> 00:06:34.130
a process referred to
as projective geometry,

165
00:06:34.130 --> 00:06:36.215
which relates
objects in the world

166
00:06:36.215 --> 00:06:39.360
to their projections
on the imaging sensor.